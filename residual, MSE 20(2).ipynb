{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N8_Multimedia_Termproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BQmYo2rqmK4"
      },
      "source": [
        "# Get Dataset from Google Drive  \n",
        "Please upload your dataset on google drive first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vxHB3wfW911",
        "outputId": "ef985104-e461-49a2-a5bb-72fa2427cc3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbDhYfKKa41s"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tqdm\n",
        "\n",
        "file_name = \"Multimedia_dataset.zip\"\n",
        "zip_path = os.path.join('/content/drive/MyDrive/Multimedia/Multimedia_dataset/Multimedia_dataset.zip')\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmbp65jgq67j"
      },
      "source": [
        "# Noise Transform  \n",
        "If you want to change how much noise you are giving, change the stddev and mean values at 'gaussian_noise' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyeUBdtKYQSu"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "\n",
        "import random\n",
        "\n",
        "class NoiseTransform(object):\n",
        "  def __init__(self, size=180, mode=\"training\"):\n",
        "    super(NoiseTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "  \n",
        "  def gaussian_noise(self, img):\n",
        "    mean = 0\n",
        "    stddev = 25\n",
        "    noise = Variable(torch.zeros(img.size()))\n",
        "    noise = noise.data.normal_(mean, stddev/255.)\n",
        "\n",
        "    return noise\n",
        "\n",
        "  def __call__(self, img):\n",
        "    if (self.mode == \"training\") | (self.mode == \"validation\"):\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      self.noise_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(self.gaussian_noise),\n",
        "      ])\n",
        "      return self.gt_transform(img), self.noise_transform(img)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.ToTensor()])\n",
        "      return self.gt_transform(img)\n",
        "    else:\n",
        "      return NotImplementedError\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGKbE7uFrWwb"
      },
      "source": [
        "# Dataloader for Noise Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxZsXXZ9YpYp"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class NoiseDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(NoiseDataset, self).__init__()\n",
        "\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = None\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = NoiseTransform(self.size, mode)\n",
        "    if mode == \"training\":\n",
        "      train_dir = os.path.join(self.root_path, \"train\")\n",
        "      self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "    elif mode == \"validation\":\n",
        "      val_dir = os.path.join(self.root_path, \"validation\")\n",
        "      self.examples = [os.path.join(self.root_path, \"validation\", dirs) for dirs in os.listdir(val_dir)]\n",
        "    elif mode == \"testing\":\n",
        "      test_dir = os.path.join(self.root_path, \"test\")\n",
        "      self.examples = [os.path.join(self.root_path, \"test\", dirs) for dirs in os.listdir(test_dir)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.examples[idx]\n",
        "    image = Image.open(file_name)\n",
        "\n",
        "\n",
        "    if self.mode == \"testing\":\n",
        "      input_img = self.transforms(image)\n",
        "      sample = {\"img\": input_img,\n",
        "                \"file_name\": \"image_%06d.png\" % int(os.path.basename(file_name).split('.')[0])}\n",
        "    else:\n",
        "      clean, noise = self.transforms(image)\n",
        "      sample = {\"img\": clean, \"noise\": noise}\n",
        "\n",
        "    return sample"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDx4vFU-rf5z"
      },
      "source": [
        "# Example for Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53tDtBFLenTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f0aaa950-8ac3-4c81-fc5f-6fce8987d3ed"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "def image_show(img):\n",
        "  if isinstance(img, torch.Tensor):\n",
        "    # PIL image로 바꿔준다.\n",
        "    img = transforms.ToPILImage()(img)\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"/content/\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = NoiseDataset(root_path, 128) #128은 size\n",
        "train_dataset.set_mode(\"training\")\n",
        "\n",
        "\n",
        "# batch=4 단위로 data를 load\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\"\"\"\n",
        "# tqdm은 진행표시바\n",
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  #CUDA는 NVIDIA에서 개발한 GPU 개발 툴로 많은 양의 연산을 동시에 처리하는 것이 목표\n",
        "  if use_cuda:\n",
        "    img = data[\"img\"].to('cuda')\n",
        "    noise = data[\"noise\"].to('cuda')\n",
        "  \n",
        "  model_input = img + noise\n",
        "\n",
        "  # clamp는 최대 최소 값을 정해주는 함수\n",
        "  # (최소~최대 범위에 포함되지 않는게 있으면 그 값을 최소 최대값으로 변경)\n",
        "  noise_image = torch.clamp(model_input, 0, 1)\n",
        "\n",
        "  image_show(img[0])\n",
        "  image_show(noise[0])\n",
        "\n",
        "\n",
        "\n",
        "  input()\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# tqdm은 진행표시바\\nfor i, data in enumerate(tqdm.tqdm(train_dataloader)):\\n  #CUDA는 NVIDIA에서 개발한 GPU 개발 툴로 많은 양의 연산을 동시에 처리하는 것이 목표\\n  if use_cuda:\\n    img = data[\"img\"].to(\\'cuda\\')\\n    noise = data[\"noise\"].to(\\'cuda\\')\\n  \\n  model_input = img + noise\\n\\n  # clamp는 최대 최소 값을 정해주는 함수\\n  # (최소~최대 범위에 포함되지 않는게 있으면 그 값을 최소 최대값으로 변경)\\n  noise_image = torch.clamp(model_input, 0, 1)\\n\\n  image_show(img[0])\\n  image_show(noise[0])\\n\\n\\n\\n  input()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtESD4NV4Wks"
      },
      "source": [
        "# UNet Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVJI37g45PLz"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "## 네트워크 구축하기\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, nch, nker=64, learning_type=\"plain\", norm=\"bnorm\"):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.learning_type = learning_type\n",
        "\n",
        "        # Contracting path\n",
        "        self.enc1_1 = CBR2d(in_channels=nch, out_channels=1 * nker, norm=norm)\n",
        "        self.enc1_2 = CBR2d(in_channels=1 * nker, out_channels=1 * nker, norm=norm)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.enc2_1 = CBR2d(in_channels=nker, out_channels=2 * nker, norm=norm)\n",
        "        self.enc2_2 = CBR2d(in_channels=2 * nker, out_channels=2 * nker, norm=norm)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.enc3_1 = CBR2d(in_channels=2 * nker, out_channels=4 * nker, norm=norm)\n",
        "        self.enc3_2 = CBR2d(in_channels=4 * nker, out_channels=4 * nker, norm=norm)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.enc4_1 = CBR2d(in_channels=4 * nker, out_channels=8 * nker, norm=norm)\n",
        "        self.enc4_2 = CBR2d(in_channels=8 * nker, out_channels=8 * nker, norm=norm)\n",
        "\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.enc5_1 = CBR2d(in_channels=8 * nker, out_channels=16 * nker, norm=norm)\n",
        "\n",
        "\n",
        "        # Expansive path\n",
        "        self.dec5_1 = CBR2d(in_channels=16 * nker, out_channels=8 * nker, norm=norm)\n",
        "\n",
        "        self.unpool4 = nn.ConvTranspose2d(in_channels=8 * nker, out_channels=8 * nker,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        self.dec4_2 = CBR2d(in_channels=2 * 8 * nker, out_channels=8 * nker, norm=norm)\n",
        "        self.dec4_1 = CBR2d(in_channels=8 * nker, out_channels=4 * nker, norm=norm)\n",
        "\n",
        "        self.unpool3 = nn.ConvTranspose2d(in_channels=4 * nker, out_channels=4 * nker,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        self.dec3_2 = CBR2d(in_channels=2 * 4 * nker, out_channels=4 * nker, norm=norm)\n",
        "        self.dec3_1 = CBR2d(in_channels=4 * nker, out_channels=2 * nker, norm=norm)\n",
        "\n",
        "        self.unpool2 = nn.ConvTranspose2d(in_channels=2 * nker, out_channels=2 * nker,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        self.dec2_2 = CBR2d(in_channels=2 * 2 * nker, out_channels=2 * nker, norm=norm)\n",
        "        self.dec2_1 = CBR2d(in_channels=2 * nker, out_channels=1 * nker, norm=norm)\n",
        "\n",
        "        self.unpool1 = nn.ConvTranspose2d(in_channels=1 * nker, out_channels=1 * nker,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        self.dec1_2 = CBR2d(in_channels=2 * 1 * nker, out_channels=1 * nker, norm=norm)\n",
        "        self.dec1_1 = CBR2d(in_channels=1 * nker, out_channels=1 * nker, norm=norm)\n",
        "\n",
        "        self.fc = nn.Conv2d(in_channels=1 * nker, out_channels=nch, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "    # Unet Layer 연결 (Forwarding)\n",
        "    # 위에서 정의한 것을 순서대로 실행한다고 생각하면 됨\n",
        "    def forward(self, x):\n",
        "        # forward encoder\n",
        "        enc1_1 = self.enc1_1(x)\n",
        "        enc1_2 = self.enc1_2(enc1_1)\n",
        "        pool1 = self.pool1(enc1_2)\n",
        "\n",
        "        enc2_1 = self.enc2_1(pool1)\n",
        "        enc2_2 = self.enc2_2(enc2_1)\n",
        "        pool2 = self.pool2(enc2_2)\n",
        "\n",
        "        enc3_1 = self.enc3_1(pool2)\n",
        "        enc3_2 = self.enc3_2(enc3_1)\n",
        "        pool3 = self.pool3(enc3_2)\n",
        "\n",
        "        enc4_1 = self.enc4_1(pool3)\n",
        "        enc4_2 = self.enc4_2(enc4_1)\n",
        "        pool4 = self.pool4(enc4_2)\n",
        "\n",
        "        enc5_1 = self.enc5_1(pool4)\n",
        "\n",
        "        # forward decoder\n",
        "        dec5_1 = self.dec5_1(enc5_1)\n",
        "\n",
        "        unpool4 = self.unpool4(dec5_1)\n",
        "        # cat은 이전 step의 output channel과 skip connection을 연결해주는 부분\n",
        "        # dim = [0: batch, 1: channel, 2: height, 3: width] <- dim은 해당 방향을 알려준다.\n",
        "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
        "        dec4_2 = self.dec4_2(cat4)\n",
        "        dec4_1 = self.dec4_1(dec4_2)\n",
        "\n",
        "        unpool3 = self.unpool3(dec4_1)\n",
        "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
        "        dec3_2 = self.dec3_2(cat3)\n",
        "        dec3_1 = self.dec3_1(dec3_2)\n",
        "\n",
        "        unpool2 = self.unpool2(dec3_1)\n",
        "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
        "        dec2_2 = self.dec2_2(cat2)\n",
        "        dec2_1 = self.dec2_1(dec2_2)\n",
        "\n",
        "        unpool1 = self.unpool1(dec2_1)\n",
        "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
        "        dec1_2 = self.dec1_2(cat1)\n",
        "        dec1_1 = self.dec1_1(dec1_2)\n",
        "\n",
        "        if self.learning_type == \"plain\":\n",
        "            x = self.fc(dec1_1)\n",
        "        elif self.learning_type == \"residual\":\n",
        "            x = x + self.fc(dec1_1)\n",
        "\n",
        "        return x\n",
        "  \n",
        "## 네트워크 저장하기\n",
        "def save(ckpt_dir, net, optim, epoch):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "\n",
        "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
        "               \"%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
        "\n",
        "## 네트워크 불러오기\n",
        "def load(ckpt_dir, net, optim):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        epoch = 0\n",
        "        return net, optim, epoch\n",
        "\n",
        "    ckpt_lst = os.listdir(ckpt_dir)\n",
        "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "\n",
        "    dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
        "\n",
        "    net.load_state_dict(dict_model['net'])\n",
        "    optim.load_state_dict(dict_model['optim'])\n",
        "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
        "\n",
        "    return net, optim, epoch\n",
        "\n",
        "# convolution, batch normalizatoin, Relu\n",
        "class CBR2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, norm=\"bnorm\", relu=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                             bias=bias)]\n",
        "\n",
        "        if not norm is None:\n",
        "            if norm == \"bnorm\":\n",
        "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "            elif norm == \"inorm\":\n",
        "                layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        if not relu is None and relu >= 0.0:\n",
        "            layers += [nn.ReLU() if relu == 0 else nn.LeakyReLU(relu)]\n",
        "\n",
        "        self.cbr = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cbr(x)\n",
        "\n",
        "\n",
        "def psnr (mse):\n",
        "  if mse == 100:\n",
        "    return 100\n",
        "  else:\n",
        "    return 20*math.log(255/math.sqrt(mse))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc-4iQd1n_Rn"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1TRomnyoB9u"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, nker=64,\n",
        "                 learning_type=\"plain\", norm=\"bnorm\", nblk=16):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.learning_type = learning_type\n",
        "\n",
        "        self.enc = CBR2d(in_channels=in_channels, out_channels= nker,\n",
        "                         kernel_size=3, stride=1, padding=1,\n",
        "                         bias=True, norm=None, relu=0.0)\n",
        "\n",
        "        # res block정의\n",
        "        res = []\n",
        "        for i in range(nblk):\n",
        "            res += [ResBlock(nker, nker, kernel_size=3, stride=1,\n",
        "                             padding=1, bias=True, norm=norm, relu=0.0)]\n",
        "        self.res = nn.Sequential(*res)\n",
        "\n",
        "        # encoder part\n",
        "        self.dec = CBR2d(nker, nker, kernel_size=3, stride=1,\n",
        "                             padding=1, bias=True, norm=norm, relu=0.0)\n",
        "\n",
        "        # single convolution layer 생성\n",
        "        self.fc = nn.Conv2d(in_channels=nker, out_channels=out_channels,\n",
        "                            kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "    # forward function\n",
        "    def forward(self, x):\n",
        "        x0 =x\n",
        "\n",
        "        x = self.enc(x)\n",
        "        x = self.res(x)\n",
        "        x = self.dec(x)\n",
        "\n",
        "        if self.learning_type == \"plain\":\n",
        "            x = self.fc(x)\n",
        "        elif self.learning_type == \"residual\":\n",
        "            x = x0 + self.fc(x)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "                 kernel_size=3, stride=1, padding=1,\n",
        "                 bias=True, norm=\"bnorm\", relu=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        layers =[]\n",
        "\n",
        "        # 1st CBR2d\n",
        "        layers += [CBR2d(in_channels, out_channels,\n",
        "                        kernel_size=kernel_size, stride=stride,\n",
        "                        padding=padding, bias=bias, norm=norm, relu=relu)]\n",
        "\n",
        "        # 2nd CBR2d\n",
        "        layers += [CBR2d(in_channels, out_channels,\n",
        "                        kernel_size=kernel_size, stride=stride,\n",
        "                        padding=padding, bias=bias, norm=norm, relu=None)]\n",
        "\n",
        "        self.resblk = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.resblk(x)\n",
        "\n",
        "\n",
        "## 네트워크 저장하기\n",
        "def save(ckpt_dir, net, optim, epoch):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "\n",
        "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
        "               \"%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
        "\n",
        "## 네트워크 불러오기\n",
        "def load(ckpt_dir, net, optim):\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        epoch = 0\n",
        "        return net, optim, epoch\n",
        "\n",
        "    ckpt_lst = os.listdir(ckpt_dir)\n",
        "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "\n",
        "    dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
        "\n",
        "    net.load_state_dict(dict_model['net'])\n",
        "    optim.load_state_dict(dict_model['optim'])\n",
        "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
        "\n",
        "    return net, optim, epoch\n",
        "\n",
        "# convolution, batch normalizatoin, Relu\n",
        "class CBR2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, norm=\"bnorm\", relu=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                             bias=bias)]\n",
        "\n",
        "        if not norm is None:\n",
        "            if norm == \"bnorm\":\n",
        "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "            elif norm == \"inorm\":\n",
        "                layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        if not relu is None and relu >= 0.0:\n",
        "            layers += [nn.ReLU() if relu == 0 else nn.LeakyReLU(relu)]\n",
        "\n",
        "        self.cbr = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cbr(x)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh1CUC654Q87"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcjIWFPo4VeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0a7a4f-0c79-4946-ad18-62d293e93758"
      },
      "source": [
        "import argparse\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#import pytorch_ssim\n",
        "!pip install pytorch_msssim \n",
        "import pytorch_msssim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "## 트레이닝 파라메터 설정하기\n",
        "train_continue = \"on\"\n",
        "\n",
        "lr = 1e-3 #learning rate\n",
        "batch_size = 20\n",
        "num_epoch = 100\n",
        "\n",
        "ckpt_dir = \"/content/drive/MyDrive/Multimedia/UNet(residual, MSE, batch20)/checkpoint/\"\n",
        "log_dir = \"/content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/log\"\n",
        "result_dir = \"/content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/result\"\n",
        "\n",
        "task = 'denoising'\n",
        "opts = ['random', 4]\n",
        "\n",
        "\n",
        "nch = 3\n",
        "nker = 64\n",
        "\n",
        "learning_type = 'residual'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "print(\"learning rate: %.4e\" % lr)\n",
        "print(\"batch size: %d\" % batch_size)\n",
        "print(\"number of epoch: %d\" % num_epoch)\n",
        "\n",
        "print(\"task: %s\" % task)\n",
        "print(\"opts: %s\" % opts)\n",
        "\n",
        "print(\"learning type: %s\" % learning_type)\n",
        "\n",
        "print(\"ckpt dir: %s\" % ckpt_dir)\n",
        "print(\"log dir: %s\" % log_dir)\n",
        "print(\"result dir: %s\" % result_dir)\n",
        "\n",
        "print(\"device: %s\" % device)\n",
        "\n",
        "## 디렉토리 생성하기\n",
        "result_dir_train = os.path.join(result_dir, 'train')\n",
        "result_dir_val = os.path.join(result_dir, 'val')\n",
        "\n",
        "if not os.path.exists(result_dir):\n",
        "    os.makedirs(os.path.join(result_dir_train, 'png'))\n",
        "    # os.makedirs(os.path.join(result_dir_train, 'numpy'))\n",
        "\n",
        "    os.makedirs(os.path.join(result_dir_val, 'png'))\n",
        "    # os.makedirs(os.path.join(result_dir_val, 'numpy'))\n",
        "\n",
        "    os.makedirs(os.path.join(result_dir_test, 'png'))\n",
        "    os.makedirs(os.path.join(result_dir_test, 'numpy'))\n",
        "\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"/content/\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "\n",
        "\n",
        "# training dataset 불러오기\n",
        "dataset_train = NoiseDataset(root_path, 128) #128은 size\n",
        "dataset_train.set_mode(\"training\")\n",
        "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# validation dataset불러오기\n",
        "dataset_val = NoiseDataset(root_path, 128) #128은 size\n",
        "dataset_val.set_mode(\"validation\")\n",
        "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# 그밖에 부수적인 variables 설정하기\n",
        "num_data_train = len(dataset_train)\n",
        "num_data_val = len(dataset_val)\n",
        "\n",
        "num_batch_train = np.ceil(num_data_train / batch_size)\n",
        "num_batch_val = np.ceil(num_data_val / batch_size)\n",
        "\n",
        "\n",
        "\n",
        "## 네트워크 생성하기\n",
        "net = UNet(nch=nch, nker=nker, learning_type=learning_type).to(device)\n",
        "#net = ResNet(in_channels= nch, out_channels = nch, nker=nker, learning_type=learning_type, nblk=16).to(device)\n",
        "\n",
        "## 손실함수 정의하기\n",
        "fn_loss = nn.MSELoss().to(device)\n",
        "#fn_loss = nn.L1Loss().to(device)\n",
        "#fn_loss = pytorch_msssim.SSIM().to(device)\n",
        "#fn_loss = MS_SSIM_L1_LOSS()\n",
        "mse_loss = nn.MSELoss().to(device)\n",
        "\n",
        "## Optimizer 설정하기\n",
        "# adam optimizer사용\n",
        "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\"\"\"\n",
        "#scheduler\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optim,\n",
        "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
        "                                        last_epoch=-1,\n",
        "                                        verbose=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "## 그밖에 부수적인 functions 설정하기\n",
        "# output을 저장하기 위해 필요한 몇가지 함수들\n",
        "\n",
        "\n",
        "# tensor에서 numpy로 변환하는 함수\n",
        "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
        "# normalize된 data를 반대로 denomalization시키는 함수\n",
        "fn_denorm = lambda x, mean, std: (x * std) + mean\n",
        "# 네트워크 output의 이미지를 binary class로 분류해주는 함수\n",
        "fn_class = lambda x: 1.0 * (x > 0.5)\n",
        "\n",
        "cmap = None\n",
        "\n",
        "\n",
        "## Tensorboard 를 사용하기 위한 SummaryWriter 설정\n",
        "writer_train = SummaryWriter(log_dir=os.path.join(log_dir, 'train'))\n",
        "writer_val: SummaryWriter = SummaryWriter(log_dir=os.path.join(log_dir, 'val'))\n",
        "\n",
        "\n",
        "## 네트워크 학습시키기\n",
        "# training이 시작되는 epoch의 시작점 0으로 세팅\n",
        "st_epoch = 0\n",
        "\n",
        "\n",
        "# TRAIN \n",
        "if train_continue == \"on\":\n",
        "    net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
        "    #사전에 저장이 된 network가 있다면 연속적으로 학습하기 위해 불러와서 사용\n",
        "\n",
        "\n",
        "# training을 한다고 network에 알림림\n",
        "for epoch in range(st_epoch + 1, num_epoch + 1):\n",
        "    net.train()\n",
        "    loss_list = []\n",
        "    loss_mse_list = []\n",
        "\n",
        "\n",
        "    # network이 input을 받아 output을 출력하는 forward pass\n",
        "    for batch, data in enumerate(loader_train, 1):\n",
        "        # forward pass\n",
        "        label = data['img'].to(device)\n",
        "        noise = data['noise'].to(device)\n",
        "\n",
        "        model_input = label + noise\n",
        "        input = torch.clamp(model_input, 0, 1)\n",
        "\n",
        "        #normalization\n",
        "        input = (input - 0.5) / 0.5\n",
        "        label = (label - 0.5) / 0.5\n",
        "\n",
        "        output = net(input)\n",
        "\n",
        "\n",
        "        # backpropagation을 한느 부분\n",
        "        # backward pass\n",
        "        optim.zero_grad()\n",
        "\n",
        "        #print(output.shape)\n",
        "        #print(label.shape)\n",
        "\n",
        "        loss = fn_loss(output, label)\n",
        "        loss_list +=[loss.item()]\n",
        "        loss.backward()\n",
        "\n",
        "        optim.step()\n",
        "        #scheduler.step() \n",
        "\n",
        "        \n",
        "        # mse loss 계산\n",
        "        loss_mse = mse_loss(output, label)\n",
        "        loss_mse_list += [loss_mse.item()]\n",
        "\n",
        "        print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | MSE LOSS %.4f | ACCURACY %.4f\" %\n",
        "              (epoch, num_epoch, batch, num_batch_train, np.mean(loss_mse_list), 1-np.mean(loss_mse_list)))\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "          # Tensorboard 저장하기\n",
        "          # Tensorboard에 input, output, label을 저장\n",
        "          label = fn_tonumpy(fn_denorm(label, mean=0.5, std=0.5))\n",
        "          input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "          output = fn_tonumpy(fn_denorm(output, mean=0.5, std=0.5))\n",
        "\n",
        "          input = np.clip(input, a_min=0, a_max=1)\n",
        "          output = np.clip(output, a_min=0, a_max=1)\n",
        "\n",
        "          id = num_batch_train * (epoch - 1) + batch\n",
        "\n",
        "          plt.imsave(os.path.join(result_dir_train, 'png', '%04d_label.png' % id), label[0].squeeze(), cmap=cmap)\n",
        "          plt.imsave(os.path.join(result_dir_train, 'png', '%04d_input.png' % id), input[0].squeeze(), cmap=cmap)\n",
        "          plt.imsave(os.path.join(result_dir_train, 'png', '%04d_output.png' % id), output[0].squeeze(), cmap=cmap)\n",
        "\n",
        "\n",
        "    # loss 를 tensorboard에 저장\n",
        "    writer_train.add_scalar('loss', np.mean(loss_mse_list), epoch)\n",
        "    \n",
        "#=============================================================================네트워크를 training하는 부분 끝\n",
        "    # network validation하는 부분\n",
        "    # validatoin부분은 backpropagation이 없기에 이를 사전에 막기 위해 torch.no_grad()를 activate 시킨다.\n",
        "    # network에게 현재 validatoin한다는 것을 알리기 위해 net.eval() 활성화\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        loss_list = []\n",
        "        loss_mse_list = []\n",
        "\n",
        "        # training과 마찬가지로 forward pass진행\n",
        "        for batch, data in enumerate(loader_val, 1):\n",
        "            # forward pass\n",
        "            label = data['img'].to(device)\n",
        "            noise = data['noise'].to(device)\n",
        "\n",
        "            model_input = label + noise\n",
        "            input = torch.clamp(model_input, 0, 1)\n",
        "\n",
        "            #normalization\n",
        "            input = (input - 0.5) / 0.5\n",
        "            label = (label - 0.5) / 0.5\n",
        "\n",
        "\n",
        "            output = net(input)\n",
        "\n",
        "\n",
        "            # 손실함수 계산하기\n",
        "            loss = fn_loss(output, label)\n",
        "\n",
        "            # 손실함수 계산\n",
        "            loss_list += [loss.item()]\n",
        "\n",
        "            # mse loss 계산\n",
        "            loss_mse = mse_loss(output, label)\n",
        "            loss_mse_list += [loss_mse.item()]\n",
        "            #loss_psnr = psnr(np.mean(loss_mse))\n",
        "            print(\"VALID: EPOCH %04d / %04d | BATCH %04d / %04d | MSE LOSS %.4f | ACCURACY %.4f\" %\n",
        "                  (epoch, num_epoch, batch, num_batch_train, np.mean(loss_mse_list), 1-np.mean(loss_mse_list)))\n",
        "            \n",
        "            if batch % 3 == 0:\n",
        "              label = fn_tonumpy(fn_denorm(label, mean=0.5, std=0.5))\n",
        "              input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "              output = fn_tonumpy(fn_denorm(output, mean=0.5, std=0.5))\n",
        "\n",
        "              input = np.clip(input, a_min=0, a_max=1)\n",
        "              output = np.clip(output, a_min=0, a_max=1)\n",
        "\n",
        "              id = num_batch_val * (epoch - 1) + batch\n",
        "\n",
        "              #결과를 png파일로 저장\n",
        "              plt.imsave(os.path.join(result_dir_val, 'png', '%04d_label.png' % id), label[0].squeeze(), cmap=cmap)\n",
        "              plt.imsave(os.path.join(result_dir_val, 'png', '%04d_input.png' % id), input[0].squeeze(), cmap=cmap)\n",
        "              plt.imsave(os.path.join(result_dir_val, 'png', '%04d_output.png' % id), output[0].squeeze(), cmap=cmap)\n",
        "\n",
        "\n",
        "    writer_val.add_scalar('loss', np.mean(loss_mse_list), epoch)\n",
        "\n",
        "    # 20번마다 한번씩 network저장\n",
        "    if epoch % 20 == 0:\n",
        "      # epoch이 진행 될 때마다 network저장\n",
        "        save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n",
        "\n",
        "writer_train.close()\n",
        "writer_val.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_msssim\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/d3/3cb0f397232cf79e1762323c3a8862e39ad53eca0bb5f6be9ccc8e7c070e/pytorch_msssim-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch_msssim) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch_msssim) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pytorch_msssim) (1.19.5)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n",
            "learning rate: 1.0000e-03\n",
            "batch size: 20\n",
            "number of epoch: 100\n",
            "task: denoising\n",
            "opts: ['random', 4]\n",
            "learning type: residual\n",
            "ckpt dir: /content/drive/MyDrive/Multimedia/UNet(residual, MSE, batch20)/checkpoint/\n",
            "log dir: /content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/log\n",
            "result dir: /content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/result\n",
            "device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0027 | ACCURACY 0.9973\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0081 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0301 | ACCURACY 0.9699\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0168 | ACCURACY 0.9832\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0123 | ACCURACY 0.9877\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0100 | ACCURACY 0.9900\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0088 | ACCURACY 0.9912\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0086 | ACCURACY 0.9914\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0079 | ACCURACY 0.9921\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0074 | ACCURACY 0.9926\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0069 | ACCURACY 0.9931\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0066 | ACCURACY 0.9934\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0064 | ACCURACY 0.9936\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0062 | ACCURACY 0.9938\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0060 | ACCURACY 0.9940\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0062 | ACCURACY 0.9938\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0060 | ACCURACY 0.9940\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0059 | ACCURACY 0.9941\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0057 | ACCURACY 0.9943\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0057 | ACCURACY 0.9943\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0056 | ACCURACY 0.9944\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0076 | ACCURACY 0.9924\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0074 | ACCURACY 0.9926\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0072 | ACCURACY 0.9928\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0070 | ACCURACY 0.9930\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0069 | ACCURACY 0.9931\n",
            "VALID: EPOCH 0081 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0068 | ACCURACY 0.9932\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0082 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0082 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0083 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0085 | ACCURACY 0.9915\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0060 | ACCURACY 0.9940\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0053 | ACCURACY 0.9947\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0044 | ACCURACY 0.9956\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0076 | ACCURACY 0.9924\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0071 | ACCURACY 0.9929\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0069 | ACCURACY 0.9931\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0064 | ACCURACY 0.9936\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0062 | ACCURACY 0.9938\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0059 | ACCURACY 0.9941\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0057 | ACCURACY 0.9943\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0056 | ACCURACY 0.9944\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0061 | ACCURACY 0.9939\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0060 | ACCURACY 0.9940\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0059 | ACCURACY 0.9941\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0058 | ACCURACY 0.9942\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0068 | ACCURACY 0.9932\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0066 | ACCURACY 0.9934\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0065 | ACCURACY 0.9935\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0063 | ACCURACY 0.9937\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0062 | ACCURACY 0.9938\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0078 | ACCURACY 0.9922\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0089 | ACCURACY 0.9911\n",
            "VALID: EPOCH 0083 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0093 | ACCURACY 0.9907\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0084 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0092 | ACCURACY 0.9908\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0073 | ACCURACY 0.9927\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0072 | ACCURACY 0.9928\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0076 | ACCURACY 0.9924\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0069 | ACCURACY 0.9931\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0065 | ACCURACY 0.9935\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0062 | ACCURACY 0.9938\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0059 | ACCURACY 0.9941\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0057 | ACCURACY 0.9943\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0054 | ACCURACY 0.9946\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0053 | ACCURACY 0.9947\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0052 | ACCURACY 0.9948\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0051 | ACCURACY 0.9949\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0046 | ACCURACY 0.9954\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0046 | ACCURACY 0.9954\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0045 | ACCURACY 0.9955\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0084 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0085 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0085 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0086 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0086 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0087 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0044 | ACCURACY 0.9956\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0042 | ACCURACY 0.9958\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0087 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0043 | ACCURACY 0.9957\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0088 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0257 | ACCURACY 0.9743\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0146 | ACCURACY 0.9854\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0111 | ACCURACY 0.9889\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0091 | ACCURACY 0.9909\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0080 | ACCURACY 0.9920\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0145 | ACCURACY 0.9855\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0130 | ACCURACY 0.9870\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0118 | ACCURACY 0.9882\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0127 | ACCURACY 0.9873\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0313 | ACCURACY 0.9687\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0293 | ACCURACY 0.9707\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0278 | ACCURACY 0.9722\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0260 | ACCURACY 0.9740\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0247 | ACCURACY 0.9753\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0233 | ACCURACY 0.9767\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0221 | ACCURACY 0.9779\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0219 | ACCURACY 0.9781\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0209 | ACCURACY 0.9791\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0200 | ACCURACY 0.9800\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0192 | ACCURACY 0.9808\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0184 | ACCURACY 0.9816\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0177 | ACCURACY 0.9823\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0173 | ACCURACY 0.9827\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0167 | ACCURACY 0.9833\n",
            "VALID: EPOCH 0088 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0162 | ACCURACY 0.9838\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0026 | ACCURACY 0.9974\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0026 | ACCURACY 0.9974\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0027 | ACCURACY 0.9973\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0089 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0091 | ACCURACY 0.9909\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0213 | ACCURACY 0.9787\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0177 | ACCURACY 0.9823\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0154 | ACCURACY 0.9846\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0137 | ACCURACY 0.9863\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0127 | ACCURACY 0.9873\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0116 | ACCURACY 0.9884\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0114 | ACCURACY 0.9886\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0107 | ACCURACY 0.9893\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0100 | ACCURACY 0.9900\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0096 | ACCURACY 0.9904\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0092 | ACCURACY 0.9908\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0088 | ACCURACY 0.9912\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0085 | ACCURACY 0.9915\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0084 | ACCURACY 0.9916\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0096 | ACCURACY 0.9904\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0093 | ACCURACY 0.9907\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0092 | ACCURACY 0.9908\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0089 | ACCURACY 0.9911\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0087 | ACCURACY 0.9913\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0085 | ACCURACY 0.9915\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0083 | ACCURACY 0.9917\n",
            "VALID: EPOCH 0089 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0081 | ACCURACY 0.9919\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0090 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0028 | ACCURACY 0.9972\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0058 | ACCURACY 0.9942\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0050 | ACCURACY 0.9950\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0056 | ACCURACY 0.9944\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0053 | ACCURACY 0.9947\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0046 | ACCURACY 0.9954\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0046 | ACCURACY 0.9954\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0045 | ACCURACY 0.9955\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0045 | ACCURACY 0.9955\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0044 | ACCURACY 0.9956\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0050 | ACCURACY 0.9950\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0049 | ACCURACY 0.9951\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0047 | ACCURACY 0.9953\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0058 | ACCURACY 0.9942\n",
            "VALID: EPOCH 0090 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0057 | ACCURACY 0.9943\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0091 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.2703 | ACCURACY 0.7297\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.1965 | ACCURACY 0.8035\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.2102 | ACCURACY 0.7898\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.2231 | ACCURACY 0.7769\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.2037 | ACCURACY 0.7963\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.2077 | ACCURACY 0.7923\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.2310 | ACCURACY 0.7690\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.2439 | ACCURACY 0.7561\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.2211 | ACCURACY 0.7789\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.2165 | ACCURACY 0.7835\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.2250 | ACCURACY 0.7750\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.2153 | ACCURACY 0.7847\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.2124 | ACCURACY 0.7876\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.2049 | ACCURACY 0.7951\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.2000 | ACCURACY 0.8000\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.1940 | ACCURACY 0.8060\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.1931 | ACCURACY 0.8069\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.1875 | ACCURACY 0.8125\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.2092 | ACCURACY 0.7908\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.2066 | ACCURACY 0.7934\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.1982 | ACCURACY 0.8018\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.1992 | ACCURACY 0.8008\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.1961 | ACCURACY 0.8039\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.1927 | ACCURACY 0.8073\n",
            "VALID: EPOCH 0091 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.1888 | ACCURACY 0.8112\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0092 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0092 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0093 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0093 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0094 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0094 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0095 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0095 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0096 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0036 | ACCURACY 0.9964\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "VALID: EPOCH 0096 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0028 | ACCURACY 0.9972\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0097 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0097 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0098 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0043 | ACCURACY 0.9957\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0053 | ACCURACY 0.9947\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0048 | ACCURACY 0.9952\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0045 | ACCURACY 0.9955\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0043 | ACCURACY 0.9957\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0042 | ACCURACY 0.9958\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0042 | ACCURACY 0.9958\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0098 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0035 | ACCURACY 0.9965\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0099 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0034 | ACCURACY 0.9966\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "VALID: EPOCH 0099 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0033 | ACCURACY 0.9967\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0028 | ACCURACY 0.9972\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0028 | ACCURACY 0.9972\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0029 | ACCURACY 0.9971\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0030 | ACCURACY 0.9970\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0026 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0027 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0028 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0029 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0030 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0031 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0032 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0033 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0034 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0035 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0036 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0037 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0038 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0039 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0040 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0041 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0042 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0043 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0044 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0045 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0046 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0047 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0048 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0049 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0050 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0051 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0052 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0053 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0054 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0055 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0056 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0057 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0058 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0059 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0060 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0061 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0062 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0063 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0064 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0065 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0066 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0067 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0068 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0069 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0070 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0071 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0072 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0073 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0074 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0075 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0076 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0077 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0078 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0079 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0080 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0081 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0082 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0083 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0084 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0085 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0086 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0087 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0088 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0089 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0090 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0091 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0092 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0093 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0094 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0095 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0096 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0097 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0098 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0099 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0100 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0101 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0102 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0103 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0104 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0105 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0106 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0107 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0108 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0109 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0110 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0111 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0112 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0113 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0114 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0115 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0116 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0117 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0118 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0119 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0120 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0121 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0122 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0123 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0124 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0125 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0126 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0127 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0128 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0129 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0130 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0131 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0132 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0133 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0134 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0135 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0136 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0137 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0138 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0139 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0140 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0141 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0142 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0143 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0144 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0145 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0146 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0147 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0148 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0149 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0150 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0151 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0152 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0153 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0154 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0155 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0156 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0157 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0158 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0159 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0160 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0161 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0162 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0163 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0164 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0165 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0166 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0167 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0168 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0169 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0170 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0171 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0172 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0173 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0174 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0175 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0176 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0177 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0178 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0179 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0180 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0181 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0182 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0183 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0184 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0185 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0186 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0187 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0188 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0189 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0190 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0191 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0192 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0193 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0194 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0195 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0196 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0197 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0198 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0199 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0200 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0201 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0202 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0203 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0204 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0205 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0206 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0207 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0208 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0209 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0210 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0211 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0212 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0213 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0214 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0215 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0216 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0217 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0218 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0219 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0220 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0221 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0222 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0223 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0224 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "TRAIN: EPOCH 0100 / 0100 | BATCH 0225 / 0225 | MSE LOSS 0.0032 | ACCURACY 0.9968\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0001 / 0225 | MSE LOSS 0.0031 | ACCURACY 0.9969\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0002 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0003 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0004 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0005 / 0225 | MSE LOSS 0.0043 | ACCURACY 0.9957\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0006 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0007 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0008 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0009 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0010 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0011 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0012 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0013 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0014 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0015 / 0225 | MSE LOSS 0.0038 | ACCURACY 0.9962\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0016 / 0225 | MSE LOSS 0.0037 | ACCURACY 0.9963\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0017 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0018 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0019 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0020 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0021 / 0225 | MSE LOSS 0.0040 | ACCURACY 0.9960\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0022 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0023 / 0225 | MSE LOSS 0.0039 | ACCURACY 0.9961\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0024 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n",
            "VALID: EPOCH 0100 / 0100 | BATCH 0025 / 0225 | MSE LOSS 0.0041 | ACCURACY 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-k_5CSnI9Ip"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOzB_NQqI_eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc71128-ecfb-4976-87d5-fc68a7f70444"
      },
      "source": [
        "import argparse\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "ckpt_dir = \"/content/drive/MyDrive/Multimedia/UNet(residual, MSE, batch20)/checkpoint\"\n",
        "log_dir = \"/content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/log\"\n",
        "result_dir = \"/content/drive/MyDrive/Multimedia/Unet(residual, MSE, batch20)/result\"\n",
        "\n",
        "## 디렉토리 생성하기\n",
        "result_dir_test = os.path.join(result_dir, 'test')\n",
        "if not os.path.exists(result_dir):\n",
        "    os.makedirs(os.path.join(result_dir_test, 'png'))\n",
        "    os.makedirs(os.path.join(result_dir_test, 'numpy'))\n",
        "\n",
        "\n",
        "dataset_test = NoiseDataset(root_path, 128) #128은 size\n",
        "dataset_test.set_mode(\"testing\")\n",
        "loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# 그밖에 부수적인 variables 설정하기\n",
        "num_data_test = len(dataset_test)\n",
        "num_batch_test = np.ceil(num_data_test / batch_size)\n",
        "\n",
        "\n",
        "\n",
        "## 네트워크 생성하기\n",
        "net = UNet(nch=nch, nker=nker, learning_type=learning_type).to(device)\n",
        "\n",
        "\n",
        "## Optimizer 설정하기\n",
        "# adam optimizer사용\n",
        "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "## 그밖에 부수적인 functions 설정하기\n",
        "# output을 저장하기 위해 필요한 몇가지 함수들\n",
        "\n",
        "\n",
        "# tensor에서 numpy로 변환하는 함수\n",
        "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
        "# normalize된 data를 반대로 denomalization시키는 함수\n",
        "fn_denorm = lambda x, mean, std: (x * std) + mean\n",
        "# 네트워크 output의 이미지를 binary class로 분류해주는 함수\n",
        "fn_class = lambda x: 1.0 * (x > 0.5)\n",
        "\n",
        "cmap = None\n",
        "\n",
        "net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
        "\n",
        "\n",
        "# backpropagation이 없기에 이를 사전에 막기 위해 torch.no_grad()를 activate 시킨다.\n",
        "# network에게 현재 validatoin한다는 것을 알리기 위해 net.eval() 활성화\n",
        "with torch.no_grad():\n",
        "    net.eval()\n",
        "    loss_mse = []\n",
        "\n",
        "    for batch, data in enumerate(loader_test, 1):\n",
        "        # forward pass\n",
        "        input = data['img'].to(device)\n",
        "        file_name = data[\"file_name\"]\n",
        "\n",
        "        #normalization\n",
        "        input = (input - 0.5) / 0.5\n",
        "\n",
        "        output = net(input)\n",
        "\n",
        "\n",
        "        print(\"TEST: BATCH %04d / %04d\" %\n",
        "              (batch, 1000))\n",
        "        \n",
        "\n",
        "        # Tensorboard 저장하기\n",
        "        input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "        output = fn_tonumpy(fn_denorm(output, mean=0.5, std=0.5))\n",
        "\n",
        "        for j in range(input.shape[0]):\n",
        "            id = batch_size * (batch - 1) + j\n",
        "\n",
        "            output_ = output[j]\n",
        "\n",
        "            # 결과를 png파일로 저장장\n",
        "            output_ = np.clip(output_, a_min=0, a_max=1)\n",
        "\n",
        "            plt.imsave(os.path.join(result_dir_test, file_name[j]), output_, cmap=cmap)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST: BATCH 0001 / 1000\n",
            "TEST: BATCH 0002 / 1000\n",
            "TEST: BATCH 0003 / 1000\n",
            "TEST: BATCH 0004 / 1000\n",
            "TEST: BATCH 0005 / 1000\n",
            "TEST: BATCH 0006 / 1000\n",
            "TEST: BATCH 0007 / 1000\n",
            "TEST: BATCH 0008 / 1000\n",
            "TEST: BATCH 0009 / 1000\n",
            "TEST: BATCH 0010 / 1000\n",
            "TEST: BATCH 0011 / 1000\n",
            "TEST: BATCH 0012 / 1000\n",
            "TEST: BATCH 0013 / 1000\n",
            "TEST: BATCH 0014 / 1000\n",
            "TEST: BATCH 0015 / 1000\n",
            "TEST: BATCH 0016 / 1000\n",
            "TEST: BATCH 0017 / 1000\n",
            "TEST: BATCH 0018 / 1000\n",
            "TEST: BATCH 0019 / 1000\n",
            "TEST: BATCH 0020 / 1000\n",
            "TEST: BATCH 0021 / 1000\n",
            "TEST: BATCH 0022 / 1000\n",
            "TEST: BATCH 0023 / 1000\n",
            "TEST: BATCH 0024 / 1000\n",
            "TEST: BATCH 0025 / 1000\n",
            "TEST: BATCH 0026 / 1000\n",
            "TEST: BATCH 0027 / 1000\n",
            "TEST: BATCH 0028 / 1000\n",
            "TEST: BATCH 0029 / 1000\n",
            "TEST: BATCH 0030 / 1000\n",
            "TEST: BATCH 0031 / 1000\n",
            "TEST: BATCH 0032 / 1000\n",
            "TEST: BATCH 0033 / 1000\n",
            "TEST: BATCH 0034 / 1000\n",
            "TEST: BATCH 0035 / 1000\n",
            "TEST: BATCH 0036 / 1000\n",
            "TEST: BATCH 0037 / 1000\n",
            "TEST: BATCH 0038 / 1000\n",
            "TEST: BATCH 0039 / 1000\n",
            "TEST: BATCH 0040 / 1000\n",
            "TEST: BATCH 0041 / 1000\n",
            "TEST: BATCH 0042 / 1000\n",
            "TEST: BATCH 0043 / 1000\n",
            "TEST: BATCH 0044 / 1000\n",
            "TEST: BATCH 0045 / 1000\n",
            "TEST: BATCH 0046 / 1000\n",
            "TEST: BATCH 0047 / 1000\n",
            "TEST: BATCH 0048 / 1000\n",
            "TEST: BATCH 0049 / 1000\n",
            "TEST: BATCH 0050 / 1000\n",
            "TEST: BATCH 0051 / 1000\n",
            "TEST: BATCH 0052 / 1000\n",
            "TEST: BATCH 0053 / 1000\n",
            "TEST: BATCH 0054 / 1000\n",
            "TEST: BATCH 0055 / 1000\n",
            "TEST: BATCH 0056 / 1000\n",
            "TEST: BATCH 0057 / 1000\n",
            "TEST: BATCH 0058 / 1000\n",
            "TEST: BATCH 0059 / 1000\n",
            "TEST: BATCH 0060 / 1000\n",
            "TEST: BATCH 0061 / 1000\n",
            "TEST: BATCH 0062 / 1000\n",
            "TEST: BATCH 0063 / 1000\n",
            "TEST: BATCH 0064 / 1000\n",
            "TEST: BATCH 0065 / 1000\n",
            "TEST: BATCH 0066 / 1000\n",
            "TEST: BATCH 0067 / 1000\n",
            "TEST: BATCH 0068 / 1000\n",
            "TEST: BATCH 0069 / 1000\n",
            "TEST: BATCH 0070 / 1000\n",
            "TEST: BATCH 0071 / 1000\n",
            "TEST: BATCH 0072 / 1000\n",
            "TEST: BATCH 0073 / 1000\n",
            "TEST: BATCH 0074 / 1000\n",
            "TEST: BATCH 0075 / 1000\n",
            "TEST: BATCH 0076 / 1000\n",
            "TEST: BATCH 0077 / 1000\n",
            "TEST: BATCH 0078 / 1000\n",
            "TEST: BATCH 0079 / 1000\n",
            "TEST: BATCH 0080 / 1000\n",
            "TEST: BATCH 0081 / 1000\n",
            "TEST: BATCH 0082 / 1000\n",
            "TEST: BATCH 0083 / 1000\n",
            "TEST: BATCH 0084 / 1000\n",
            "TEST: BATCH 0085 / 1000\n",
            "TEST: BATCH 0086 / 1000\n",
            "TEST: BATCH 0087 / 1000\n",
            "TEST: BATCH 0088 / 1000\n",
            "TEST: BATCH 0089 / 1000\n",
            "TEST: BATCH 0090 / 1000\n",
            "TEST: BATCH 0091 / 1000\n",
            "TEST: BATCH 0092 / 1000\n",
            "TEST: BATCH 0093 / 1000\n",
            "TEST: BATCH 0094 / 1000\n",
            "TEST: BATCH 0095 / 1000\n",
            "TEST: BATCH 0096 / 1000\n",
            "TEST: BATCH 0097 / 1000\n",
            "TEST: BATCH 0098 / 1000\n",
            "TEST: BATCH 0099 / 1000\n",
            "TEST: BATCH 0100 / 1000\n",
            "TEST: BATCH 0101 / 1000\n",
            "TEST: BATCH 0102 / 1000\n",
            "TEST: BATCH 0103 / 1000\n",
            "TEST: BATCH 0104 / 1000\n",
            "TEST: BATCH 0105 / 1000\n",
            "TEST: BATCH 0106 / 1000\n",
            "TEST: BATCH 0107 / 1000\n",
            "TEST: BATCH 0108 / 1000\n",
            "TEST: BATCH 0109 / 1000\n",
            "TEST: BATCH 0110 / 1000\n",
            "TEST: BATCH 0111 / 1000\n",
            "TEST: BATCH 0112 / 1000\n",
            "TEST: BATCH 0113 / 1000\n",
            "TEST: BATCH 0114 / 1000\n",
            "TEST: BATCH 0115 / 1000\n",
            "TEST: BATCH 0116 / 1000\n",
            "TEST: BATCH 0117 / 1000\n",
            "TEST: BATCH 0118 / 1000\n",
            "TEST: BATCH 0119 / 1000\n",
            "TEST: BATCH 0120 / 1000\n",
            "TEST: BATCH 0121 / 1000\n",
            "TEST: BATCH 0122 / 1000\n",
            "TEST: BATCH 0123 / 1000\n",
            "TEST: BATCH 0124 / 1000\n",
            "TEST: BATCH 0125 / 1000\n",
            "TEST: BATCH 0126 / 1000\n",
            "TEST: BATCH 0127 / 1000\n",
            "TEST: BATCH 0128 / 1000\n",
            "TEST: BATCH 0129 / 1000\n",
            "TEST: BATCH 0130 / 1000\n",
            "TEST: BATCH 0131 / 1000\n",
            "TEST: BATCH 0132 / 1000\n",
            "TEST: BATCH 0133 / 1000\n",
            "TEST: BATCH 0134 / 1000\n",
            "TEST: BATCH 0135 / 1000\n",
            "TEST: BATCH 0136 / 1000\n",
            "TEST: BATCH 0137 / 1000\n",
            "TEST: BATCH 0138 / 1000\n",
            "TEST: BATCH 0139 / 1000\n",
            "TEST: BATCH 0140 / 1000\n",
            "TEST: BATCH 0141 / 1000\n",
            "TEST: BATCH 0142 / 1000\n",
            "TEST: BATCH 0143 / 1000\n",
            "TEST: BATCH 0144 / 1000\n",
            "TEST: BATCH 0145 / 1000\n",
            "TEST: BATCH 0146 / 1000\n",
            "TEST: BATCH 0147 / 1000\n",
            "TEST: BATCH 0148 / 1000\n",
            "TEST: BATCH 0149 / 1000\n",
            "TEST: BATCH 0150 / 1000\n",
            "TEST: BATCH 0151 / 1000\n",
            "TEST: BATCH 0152 / 1000\n",
            "TEST: BATCH 0153 / 1000\n",
            "TEST: BATCH 0154 / 1000\n",
            "TEST: BATCH 0155 / 1000\n",
            "TEST: BATCH 0156 / 1000\n",
            "TEST: BATCH 0157 / 1000\n",
            "TEST: BATCH 0158 / 1000\n",
            "TEST: BATCH 0159 / 1000\n",
            "TEST: BATCH 0160 / 1000\n",
            "TEST: BATCH 0161 / 1000\n",
            "TEST: BATCH 0162 / 1000\n",
            "TEST: BATCH 0163 / 1000\n",
            "TEST: BATCH 0164 / 1000\n",
            "TEST: BATCH 0165 / 1000\n",
            "TEST: BATCH 0166 / 1000\n",
            "TEST: BATCH 0167 / 1000\n",
            "TEST: BATCH 0168 / 1000\n",
            "TEST: BATCH 0169 / 1000\n",
            "TEST: BATCH 0170 / 1000\n",
            "TEST: BATCH 0171 / 1000\n",
            "TEST: BATCH 0172 / 1000\n",
            "TEST: BATCH 0173 / 1000\n",
            "TEST: BATCH 0174 / 1000\n",
            "TEST: BATCH 0175 / 1000\n",
            "TEST: BATCH 0176 / 1000\n",
            "TEST: BATCH 0177 / 1000\n",
            "TEST: BATCH 0178 / 1000\n",
            "TEST: BATCH 0179 / 1000\n",
            "TEST: BATCH 0180 / 1000\n",
            "TEST: BATCH 0181 / 1000\n",
            "TEST: BATCH 0182 / 1000\n",
            "TEST: BATCH 0183 / 1000\n",
            "TEST: BATCH 0184 / 1000\n",
            "TEST: BATCH 0185 / 1000\n",
            "TEST: BATCH 0186 / 1000\n",
            "TEST: BATCH 0187 / 1000\n",
            "TEST: BATCH 0188 / 1000\n",
            "TEST: BATCH 0189 / 1000\n",
            "TEST: BATCH 0190 / 1000\n",
            "TEST: BATCH 0191 / 1000\n",
            "TEST: BATCH 0192 / 1000\n",
            "TEST: BATCH 0193 / 1000\n",
            "TEST: BATCH 0194 / 1000\n",
            "TEST: BATCH 0195 / 1000\n",
            "TEST: BATCH 0196 / 1000\n",
            "TEST: BATCH 0197 / 1000\n",
            "TEST: BATCH 0198 / 1000\n",
            "TEST: BATCH 0199 / 1000\n",
            "TEST: BATCH 0200 / 1000\n",
            "TEST: BATCH 0201 / 1000\n",
            "TEST: BATCH 0202 / 1000\n",
            "TEST: BATCH 0203 / 1000\n",
            "TEST: BATCH 0204 / 1000\n",
            "TEST: BATCH 0205 / 1000\n",
            "TEST: BATCH 0206 / 1000\n",
            "TEST: BATCH 0207 / 1000\n",
            "TEST: BATCH 0208 / 1000\n",
            "TEST: BATCH 0209 / 1000\n",
            "TEST: BATCH 0210 / 1000\n",
            "TEST: BATCH 0211 / 1000\n",
            "TEST: BATCH 0212 / 1000\n",
            "TEST: BATCH 0213 / 1000\n",
            "TEST: BATCH 0214 / 1000\n",
            "TEST: BATCH 0215 / 1000\n",
            "TEST: BATCH 0216 / 1000\n",
            "TEST: BATCH 0217 / 1000\n",
            "TEST: BATCH 0218 / 1000\n",
            "TEST: BATCH 0219 / 1000\n",
            "TEST: BATCH 0220 / 1000\n",
            "TEST: BATCH 0221 / 1000\n",
            "TEST: BATCH 0222 / 1000\n",
            "TEST: BATCH 0223 / 1000\n",
            "TEST: BATCH 0224 / 1000\n",
            "TEST: BATCH 0225 / 1000\n",
            "TEST: BATCH 0226 / 1000\n",
            "TEST: BATCH 0227 / 1000\n",
            "TEST: BATCH 0228 / 1000\n",
            "TEST: BATCH 0229 / 1000\n",
            "TEST: BATCH 0230 / 1000\n",
            "TEST: BATCH 0231 / 1000\n",
            "TEST: BATCH 0232 / 1000\n",
            "TEST: BATCH 0233 / 1000\n",
            "TEST: BATCH 0234 / 1000\n",
            "TEST: BATCH 0235 / 1000\n",
            "TEST: BATCH 0236 / 1000\n",
            "TEST: BATCH 0237 / 1000\n",
            "TEST: BATCH 0238 / 1000\n",
            "TEST: BATCH 0239 / 1000\n",
            "TEST: BATCH 0240 / 1000\n",
            "TEST: BATCH 0241 / 1000\n",
            "TEST: BATCH 0242 / 1000\n",
            "TEST: BATCH 0243 / 1000\n",
            "TEST: BATCH 0244 / 1000\n",
            "TEST: BATCH 0245 / 1000\n",
            "TEST: BATCH 0246 / 1000\n",
            "TEST: BATCH 0247 / 1000\n",
            "TEST: BATCH 0248 / 1000\n",
            "TEST: BATCH 0249 / 1000\n",
            "TEST: BATCH 0250 / 1000\n",
            "TEST: BATCH 0251 / 1000\n",
            "TEST: BATCH 0252 / 1000\n",
            "TEST: BATCH 0253 / 1000\n",
            "TEST: BATCH 0254 / 1000\n",
            "TEST: BATCH 0255 / 1000\n",
            "TEST: BATCH 0256 / 1000\n",
            "TEST: BATCH 0257 / 1000\n",
            "TEST: BATCH 0258 / 1000\n",
            "TEST: BATCH 0259 / 1000\n",
            "TEST: BATCH 0260 / 1000\n",
            "TEST: BATCH 0261 / 1000\n",
            "TEST: BATCH 0262 / 1000\n",
            "TEST: BATCH 0263 / 1000\n",
            "TEST: BATCH 0264 / 1000\n",
            "TEST: BATCH 0265 / 1000\n",
            "TEST: BATCH 0266 / 1000\n",
            "TEST: BATCH 0267 / 1000\n",
            "TEST: BATCH 0268 / 1000\n",
            "TEST: BATCH 0269 / 1000\n",
            "TEST: BATCH 0270 / 1000\n",
            "TEST: BATCH 0271 / 1000\n",
            "TEST: BATCH 0272 / 1000\n",
            "TEST: BATCH 0273 / 1000\n",
            "TEST: BATCH 0274 / 1000\n",
            "TEST: BATCH 0275 / 1000\n",
            "TEST: BATCH 0276 / 1000\n",
            "TEST: BATCH 0277 / 1000\n",
            "TEST: BATCH 0278 / 1000\n",
            "TEST: BATCH 0279 / 1000\n",
            "TEST: BATCH 0280 / 1000\n",
            "TEST: BATCH 0281 / 1000\n",
            "TEST: BATCH 0282 / 1000\n",
            "TEST: BATCH 0283 / 1000\n",
            "TEST: BATCH 0284 / 1000\n",
            "TEST: BATCH 0285 / 1000\n",
            "TEST: BATCH 0286 / 1000\n",
            "TEST: BATCH 0287 / 1000\n",
            "TEST: BATCH 0288 / 1000\n",
            "TEST: BATCH 0289 / 1000\n",
            "TEST: BATCH 0290 / 1000\n",
            "TEST: BATCH 0291 / 1000\n",
            "TEST: BATCH 0292 / 1000\n",
            "TEST: BATCH 0293 / 1000\n",
            "TEST: BATCH 0294 / 1000\n",
            "TEST: BATCH 0295 / 1000\n",
            "TEST: BATCH 0296 / 1000\n",
            "TEST: BATCH 0297 / 1000\n",
            "TEST: BATCH 0298 / 1000\n",
            "TEST: BATCH 0299 / 1000\n",
            "TEST: BATCH 0300 / 1000\n",
            "TEST: BATCH 0301 / 1000\n",
            "TEST: BATCH 0302 / 1000\n",
            "TEST: BATCH 0303 / 1000\n",
            "TEST: BATCH 0304 / 1000\n",
            "TEST: BATCH 0305 / 1000\n",
            "TEST: BATCH 0306 / 1000\n",
            "TEST: BATCH 0307 / 1000\n",
            "TEST: BATCH 0308 / 1000\n",
            "TEST: BATCH 0309 / 1000\n",
            "TEST: BATCH 0310 / 1000\n",
            "TEST: BATCH 0311 / 1000\n",
            "TEST: BATCH 0312 / 1000\n",
            "TEST: BATCH 0313 / 1000\n",
            "TEST: BATCH 0314 / 1000\n",
            "TEST: BATCH 0315 / 1000\n",
            "TEST: BATCH 0316 / 1000\n",
            "TEST: BATCH 0317 / 1000\n",
            "TEST: BATCH 0318 / 1000\n",
            "TEST: BATCH 0319 / 1000\n",
            "TEST: BATCH 0320 / 1000\n",
            "TEST: BATCH 0321 / 1000\n",
            "TEST: BATCH 0322 / 1000\n",
            "TEST: BATCH 0323 / 1000\n",
            "TEST: BATCH 0324 / 1000\n",
            "TEST: BATCH 0325 / 1000\n",
            "TEST: BATCH 0326 / 1000\n",
            "TEST: BATCH 0327 / 1000\n",
            "TEST: BATCH 0328 / 1000\n",
            "TEST: BATCH 0329 / 1000\n",
            "TEST: BATCH 0330 / 1000\n",
            "TEST: BATCH 0331 / 1000\n",
            "TEST: BATCH 0332 / 1000\n",
            "TEST: BATCH 0333 / 1000\n",
            "TEST: BATCH 0334 / 1000\n",
            "TEST: BATCH 0335 / 1000\n",
            "TEST: BATCH 0336 / 1000\n",
            "TEST: BATCH 0337 / 1000\n",
            "TEST: BATCH 0338 / 1000\n",
            "TEST: BATCH 0339 / 1000\n",
            "TEST: BATCH 0340 / 1000\n",
            "TEST: BATCH 0341 / 1000\n",
            "TEST: BATCH 0342 / 1000\n",
            "TEST: BATCH 0343 / 1000\n",
            "TEST: BATCH 0344 / 1000\n",
            "TEST: BATCH 0345 / 1000\n",
            "TEST: BATCH 0346 / 1000\n",
            "TEST: BATCH 0347 / 1000\n",
            "TEST: BATCH 0348 / 1000\n",
            "TEST: BATCH 0349 / 1000\n",
            "TEST: BATCH 0350 / 1000\n",
            "TEST: BATCH 0351 / 1000\n",
            "TEST: BATCH 0352 / 1000\n",
            "TEST: BATCH 0353 / 1000\n",
            "TEST: BATCH 0354 / 1000\n",
            "TEST: BATCH 0355 / 1000\n",
            "TEST: BATCH 0356 / 1000\n",
            "TEST: BATCH 0357 / 1000\n",
            "TEST: BATCH 0358 / 1000\n",
            "TEST: BATCH 0359 / 1000\n",
            "TEST: BATCH 0360 / 1000\n",
            "TEST: BATCH 0361 / 1000\n",
            "TEST: BATCH 0362 / 1000\n",
            "TEST: BATCH 0363 / 1000\n",
            "TEST: BATCH 0364 / 1000\n",
            "TEST: BATCH 0365 / 1000\n",
            "TEST: BATCH 0366 / 1000\n",
            "TEST: BATCH 0367 / 1000\n",
            "TEST: BATCH 0368 / 1000\n",
            "TEST: BATCH 0369 / 1000\n",
            "TEST: BATCH 0370 / 1000\n",
            "TEST: BATCH 0371 / 1000\n",
            "TEST: BATCH 0372 / 1000\n",
            "TEST: BATCH 0373 / 1000\n",
            "TEST: BATCH 0374 / 1000\n",
            "TEST: BATCH 0375 / 1000\n",
            "TEST: BATCH 0376 / 1000\n",
            "TEST: BATCH 0377 / 1000\n",
            "TEST: BATCH 0378 / 1000\n",
            "TEST: BATCH 0379 / 1000\n",
            "TEST: BATCH 0380 / 1000\n",
            "TEST: BATCH 0381 / 1000\n",
            "TEST: BATCH 0382 / 1000\n",
            "TEST: BATCH 0383 / 1000\n",
            "TEST: BATCH 0384 / 1000\n",
            "TEST: BATCH 0385 / 1000\n",
            "TEST: BATCH 0386 / 1000\n",
            "TEST: BATCH 0387 / 1000\n",
            "TEST: BATCH 0388 / 1000\n",
            "TEST: BATCH 0389 / 1000\n",
            "TEST: BATCH 0390 / 1000\n",
            "TEST: BATCH 0391 / 1000\n",
            "TEST: BATCH 0392 / 1000\n",
            "TEST: BATCH 0393 / 1000\n",
            "TEST: BATCH 0394 / 1000\n",
            "TEST: BATCH 0395 / 1000\n",
            "TEST: BATCH 0396 / 1000\n",
            "TEST: BATCH 0397 / 1000\n",
            "TEST: BATCH 0398 / 1000\n",
            "TEST: BATCH 0399 / 1000\n",
            "TEST: BATCH 0400 / 1000\n",
            "TEST: BATCH 0401 / 1000\n",
            "TEST: BATCH 0402 / 1000\n",
            "TEST: BATCH 0403 / 1000\n",
            "TEST: BATCH 0404 / 1000\n",
            "TEST: BATCH 0405 / 1000\n",
            "TEST: BATCH 0406 / 1000\n",
            "TEST: BATCH 0407 / 1000\n",
            "TEST: BATCH 0408 / 1000\n",
            "TEST: BATCH 0409 / 1000\n",
            "TEST: BATCH 0410 / 1000\n",
            "TEST: BATCH 0411 / 1000\n",
            "TEST: BATCH 0412 / 1000\n",
            "TEST: BATCH 0413 / 1000\n",
            "TEST: BATCH 0414 / 1000\n",
            "TEST: BATCH 0415 / 1000\n",
            "TEST: BATCH 0416 / 1000\n",
            "TEST: BATCH 0417 / 1000\n",
            "TEST: BATCH 0418 / 1000\n",
            "TEST: BATCH 0419 / 1000\n",
            "TEST: BATCH 0420 / 1000\n",
            "TEST: BATCH 0421 / 1000\n",
            "TEST: BATCH 0422 / 1000\n",
            "TEST: BATCH 0423 / 1000\n",
            "TEST: BATCH 0424 / 1000\n",
            "TEST: BATCH 0425 / 1000\n",
            "TEST: BATCH 0426 / 1000\n",
            "TEST: BATCH 0427 / 1000\n",
            "TEST: BATCH 0428 / 1000\n",
            "TEST: BATCH 0429 / 1000\n",
            "TEST: BATCH 0430 / 1000\n",
            "TEST: BATCH 0431 / 1000\n",
            "TEST: BATCH 0432 / 1000\n",
            "TEST: BATCH 0433 / 1000\n",
            "TEST: BATCH 0434 / 1000\n",
            "TEST: BATCH 0435 / 1000\n",
            "TEST: BATCH 0436 / 1000\n",
            "TEST: BATCH 0437 / 1000\n",
            "TEST: BATCH 0438 / 1000\n",
            "TEST: BATCH 0439 / 1000\n",
            "TEST: BATCH 0440 / 1000\n",
            "TEST: BATCH 0441 / 1000\n",
            "TEST: BATCH 0442 / 1000\n",
            "TEST: BATCH 0443 / 1000\n",
            "TEST: BATCH 0444 / 1000\n",
            "TEST: BATCH 0445 / 1000\n",
            "TEST: BATCH 0446 / 1000\n",
            "TEST: BATCH 0447 / 1000\n",
            "TEST: BATCH 0448 / 1000\n",
            "TEST: BATCH 0449 / 1000\n",
            "TEST: BATCH 0450 / 1000\n",
            "TEST: BATCH 0451 / 1000\n",
            "TEST: BATCH 0452 / 1000\n",
            "TEST: BATCH 0453 / 1000\n",
            "TEST: BATCH 0454 / 1000\n",
            "TEST: BATCH 0455 / 1000\n",
            "TEST: BATCH 0456 / 1000\n",
            "TEST: BATCH 0457 / 1000\n",
            "TEST: BATCH 0458 / 1000\n",
            "TEST: BATCH 0459 / 1000\n",
            "TEST: BATCH 0460 / 1000\n",
            "TEST: BATCH 0461 / 1000\n",
            "TEST: BATCH 0462 / 1000\n",
            "TEST: BATCH 0463 / 1000\n",
            "TEST: BATCH 0464 / 1000\n",
            "TEST: BATCH 0465 / 1000\n",
            "TEST: BATCH 0466 / 1000\n",
            "TEST: BATCH 0467 / 1000\n",
            "TEST: BATCH 0468 / 1000\n",
            "TEST: BATCH 0469 / 1000\n",
            "TEST: BATCH 0470 / 1000\n",
            "TEST: BATCH 0471 / 1000\n",
            "TEST: BATCH 0472 / 1000\n",
            "TEST: BATCH 0473 / 1000\n",
            "TEST: BATCH 0474 / 1000\n",
            "TEST: BATCH 0475 / 1000\n",
            "TEST: BATCH 0476 / 1000\n",
            "TEST: BATCH 0477 / 1000\n",
            "TEST: BATCH 0478 / 1000\n",
            "TEST: BATCH 0479 / 1000\n",
            "TEST: BATCH 0480 / 1000\n",
            "TEST: BATCH 0481 / 1000\n",
            "TEST: BATCH 0482 / 1000\n",
            "TEST: BATCH 0483 / 1000\n",
            "TEST: BATCH 0484 / 1000\n",
            "TEST: BATCH 0485 / 1000\n",
            "TEST: BATCH 0486 / 1000\n",
            "TEST: BATCH 0487 / 1000\n",
            "TEST: BATCH 0488 / 1000\n",
            "TEST: BATCH 0489 / 1000\n",
            "TEST: BATCH 0490 / 1000\n",
            "TEST: BATCH 0491 / 1000\n",
            "TEST: BATCH 0492 / 1000\n",
            "TEST: BATCH 0493 / 1000\n",
            "TEST: BATCH 0494 / 1000\n",
            "TEST: BATCH 0495 / 1000\n",
            "TEST: BATCH 0496 / 1000\n",
            "TEST: BATCH 0497 / 1000\n",
            "TEST: BATCH 0498 / 1000\n",
            "TEST: BATCH 0499 / 1000\n",
            "TEST: BATCH 0500 / 1000\n",
            "TEST: BATCH 0501 / 1000\n",
            "TEST: BATCH 0502 / 1000\n",
            "TEST: BATCH 0503 / 1000\n",
            "TEST: BATCH 0504 / 1000\n",
            "TEST: BATCH 0505 / 1000\n",
            "TEST: BATCH 0506 / 1000\n",
            "TEST: BATCH 0507 / 1000\n",
            "TEST: BATCH 0508 / 1000\n",
            "TEST: BATCH 0509 / 1000\n",
            "TEST: BATCH 0510 / 1000\n",
            "TEST: BATCH 0511 / 1000\n",
            "TEST: BATCH 0512 / 1000\n",
            "TEST: BATCH 0513 / 1000\n",
            "TEST: BATCH 0514 / 1000\n",
            "TEST: BATCH 0515 / 1000\n",
            "TEST: BATCH 0516 / 1000\n",
            "TEST: BATCH 0517 / 1000\n",
            "TEST: BATCH 0518 / 1000\n",
            "TEST: BATCH 0519 / 1000\n",
            "TEST: BATCH 0520 / 1000\n",
            "TEST: BATCH 0521 / 1000\n",
            "TEST: BATCH 0522 / 1000\n",
            "TEST: BATCH 0523 / 1000\n",
            "TEST: BATCH 0524 / 1000\n",
            "TEST: BATCH 0525 / 1000\n",
            "TEST: BATCH 0526 / 1000\n",
            "TEST: BATCH 0527 / 1000\n",
            "TEST: BATCH 0528 / 1000\n",
            "TEST: BATCH 0529 / 1000\n",
            "TEST: BATCH 0530 / 1000\n",
            "TEST: BATCH 0531 / 1000\n",
            "TEST: BATCH 0532 / 1000\n",
            "TEST: BATCH 0533 / 1000\n",
            "TEST: BATCH 0534 / 1000\n",
            "TEST: BATCH 0535 / 1000\n",
            "TEST: BATCH 0536 / 1000\n",
            "TEST: BATCH 0537 / 1000\n",
            "TEST: BATCH 0538 / 1000\n",
            "TEST: BATCH 0539 / 1000\n",
            "TEST: BATCH 0540 / 1000\n",
            "TEST: BATCH 0541 / 1000\n",
            "TEST: BATCH 0542 / 1000\n",
            "TEST: BATCH 0543 / 1000\n",
            "TEST: BATCH 0544 / 1000\n",
            "TEST: BATCH 0545 / 1000\n",
            "TEST: BATCH 0546 / 1000\n",
            "TEST: BATCH 0547 / 1000\n",
            "TEST: BATCH 0548 / 1000\n",
            "TEST: BATCH 0549 / 1000\n",
            "TEST: BATCH 0550 / 1000\n",
            "TEST: BATCH 0551 / 1000\n",
            "TEST: BATCH 0552 / 1000\n",
            "TEST: BATCH 0553 / 1000\n",
            "TEST: BATCH 0554 / 1000\n",
            "TEST: BATCH 0555 / 1000\n",
            "TEST: BATCH 0556 / 1000\n",
            "TEST: BATCH 0557 / 1000\n",
            "TEST: BATCH 0558 / 1000\n",
            "TEST: BATCH 0559 / 1000\n",
            "TEST: BATCH 0560 / 1000\n",
            "TEST: BATCH 0561 / 1000\n",
            "TEST: BATCH 0562 / 1000\n",
            "TEST: BATCH 0563 / 1000\n",
            "TEST: BATCH 0564 / 1000\n",
            "TEST: BATCH 0565 / 1000\n",
            "TEST: BATCH 0566 / 1000\n",
            "TEST: BATCH 0567 / 1000\n",
            "TEST: BATCH 0568 / 1000\n",
            "TEST: BATCH 0569 / 1000\n",
            "TEST: BATCH 0570 / 1000\n",
            "TEST: BATCH 0571 / 1000\n",
            "TEST: BATCH 0572 / 1000\n",
            "TEST: BATCH 0573 / 1000\n",
            "TEST: BATCH 0574 / 1000\n",
            "TEST: BATCH 0575 / 1000\n",
            "TEST: BATCH 0576 / 1000\n",
            "TEST: BATCH 0577 / 1000\n",
            "TEST: BATCH 0578 / 1000\n",
            "TEST: BATCH 0579 / 1000\n",
            "TEST: BATCH 0580 / 1000\n",
            "TEST: BATCH 0581 / 1000\n",
            "TEST: BATCH 0582 / 1000\n",
            "TEST: BATCH 0583 / 1000\n",
            "TEST: BATCH 0584 / 1000\n",
            "TEST: BATCH 0585 / 1000\n",
            "TEST: BATCH 0586 / 1000\n",
            "TEST: BATCH 0587 / 1000\n",
            "TEST: BATCH 0588 / 1000\n",
            "TEST: BATCH 0589 / 1000\n",
            "TEST: BATCH 0590 / 1000\n",
            "TEST: BATCH 0591 / 1000\n",
            "TEST: BATCH 0592 / 1000\n",
            "TEST: BATCH 0593 / 1000\n",
            "TEST: BATCH 0594 / 1000\n",
            "TEST: BATCH 0595 / 1000\n",
            "TEST: BATCH 0596 / 1000\n",
            "TEST: BATCH 0597 / 1000\n",
            "TEST: BATCH 0598 / 1000\n",
            "TEST: BATCH 0599 / 1000\n",
            "TEST: BATCH 0600 / 1000\n",
            "TEST: BATCH 0601 / 1000\n",
            "TEST: BATCH 0602 / 1000\n",
            "TEST: BATCH 0603 / 1000\n",
            "TEST: BATCH 0604 / 1000\n",
            "TEST: BATCH 0605 / 1000\n",
            "TEST: BATCH 0606 / 1000\n",
            "TEST: BATCH 0607 / 1000\n",
            "TEST: BATCH 0608 / 1000\n",
            "TEST: BATCH 0609 / 1000\n",
            "TEST: BATCH 0610 / 1000\n",
            "TEST: BATCH 0611 / 1000\n",
            "TEST: BATCH 0612 / 1000\n",
            "TEST: BATCH 0613 / 1000\n",
            "TEST: BATCH 0614 / 1000\n",
            "TEST: BATCH 0615 / 1000\n",
            "TEST: BATCH 0616 / 1000\n",
            "TEST: BATCH 0617 / 1000\n",
            "TEST: BATCH 0618 / 1000\n",
            "TEST: BATCH 0619 / 1000\n",
            "TEST: BATCH 0620 / 1000\n",
            "TEST: BATCH 0621 / 1000\n",
            "TEST: BATCH 0622 / 1000\n",
            "TEST: BATCH 0623 / 1000\n",
            "TEST: BATCH 0624 / 1000\n",
            "TEST: BATCH 0625 / 1000\n",
            "TEST: BATCH 0626 / 1000\n",
            "TEST: BATCH 0627 / 1000\n",
            "TEST: BATCH 0628 / 1000\n",
            "TEST: BATCH 0629 / 1000\n",
            "TEST: BATCH 0630 / 1000\n",
            "TEST: BATCH 0631 / 1000\n",
            "TEST: BATCH 0632 / 1000\n",
            "TEST: BATCH 0633 / 1000\n",
            "TEST: BATCH 0634 / 1000\n",
            "TEST: BATCH 0635 / 1000\n",
            "TEST: BATCH 0636 / 1000\n",
            "TEST: BATCH 0637 / 1000\n",
            "TEST: BATCH 0638 / 1000\n",
            "TEST: BATCH 0639 / 1000\n",
            "TEST: BATCH 0640 / 1000\n",
            "TEST: BATCH 0641 / 1000\n",
            "TEST: BATCH 0642 / 1000\n",
            "TEST: BATCH 0643 / 1000\n",
            "TEST: BATCH 0644 / 1000\n",
            "TEST: BATCH 0645 / 1000\n",
            "TEST: BATCH 0646 / 1000\n",
            "TEST: BATCH 0647 / 1000\n",
            "TEST: BATCH 0648 / 1000\n",
            "TEST: BATCH 0649 / 1000\n",
            "TEST: BATCH 0650 / 1000\n",
            "TEST: BATCH 0651 / 1000\n",
            "TEST: BATCH 0652 / 1000\n",
            "TEST: BATCH 0653 / 1000\n",
            "TEST: BATCH 0654 / 1000\n",
            "TEST: BATCH 0655 / 1000\n",
            "TEST: BATCH 0656 / 1000\n",
            "TEST: BATCH 0657 / 1000\n",
            "TEST: BATCH 0658 / 1000\n",
            "TEST: BATCH 0659 / 1000\n",
            "TEST: BATCH 0660 / 1000\n",
            "TEST: BATCH 0661 / 1000\n",
            "TEST: BATCH 0662 / 1000\n",
            "TEST: BATCH 0663 / 1000\n",
            "TEST: BATCH 0664 / 1000\n",
            "TEST: BATCH 0665 / 1000\n",
            "TEST: BATCH 0666 / 1000\n",
            "TEST: BATCH 0667 / 1000\n",
            "TEST: BATCH 0668 / 1000\n",
            "TEST: BATCH 0669 / 1000\n",
            "TEST: BATCH 0670 / 1000\n",
            "TEST: BATCH 0671 / 1000\n",
            "TEST: BATCH 0672 / 1000\n",
            "TEST: BATCH 0673 / 1000\n",
            "TEST: BATCH 0674 / 1000\n",
            "TEST: BATCH 0675 / 1000\n",
            "TEST: BATCH 0676 / 1000\n",
            "TEST: BATCH 0677 / 1000\n",
            "TEST: BATCH 0678 / 1000\n",
            "TEST: BATCH 0679 / 1000\n",
            "TEST: BATCH 0680 / 1000\n",
            "TEST: BATCH 0681 / 1000\n",
            "TEST: BATCH 0682 / 1000\n",
            "TEST: BATCH 0683 / 1000\n",
            "TEST: BATCH 0684 / 1000\n",
            "TEST: BATCH 0685 / 1000\n",
            "TEST: BATCH 0686 / 1000\n",
            "TEST: BATCH 0687 / 1000\n",
            "TEST: BATCH 0688 / 1000\n",
            "TEST: BATCH 0689 / 1000\n",
            "TEST: BATCH 0690 / 1000\n",
            "TEST: BATCH 0691 / 1000\n",
            "TEST: BATCH 0692 / 1000\n",
            "TEST: BATCH 0693 / 1000\n",
            "TEST: BATCH 0694 / 1000\n",
            "TEST: BATCH 0695 / 1000\n",
            "TEST: BATCH 0696 / 1000\n",
            "TEST: BATCH 0697 / 1000\n",
            "TEST: BATCH 0698 / 1000\n",
            "TEST: BATCH 0699 / 1000\n",
            "TEST: BATCH 0700 / 1000\n",
            "TEST: BATCH 0701 / 1000\n",
            "TEST: BATCH 0702 / 1000\n",
            "TEST: BATCH 0703 / 1000\n",
            "TEST: BATCH 0704 / 1000\n",
            "TEST: BATCH 0705 / 1000\n",
            "TEST: BATCH 0706 / 1000\n",
            "TEST: BATCH 0707 / 1000\n",
            "TEST: BATCH 0708 / 1000\n",
            "TEST: BATCH 0709 / 1000\n",
            "TEST: BATCH 0710 / 1000\n",
            "TEST: BATCH 0711 / 1000\n",
            "TEST: BATCH 0712 / 1000\n",
            "TEST: BATCH 0713 / 1000\n",
            "TEST: BATCH 0714 / 1000\n",
            "TEST: BATCH 0715 / 1000\n",
            "TEST: BATCH 0716 / 1000\n",
            "TEST: BATCH 0717 / 1000\n",
            "TEST: BATCH 0718 / 1000\n",
            "TEST: BATCH 0719 / 1000\n",
            "TEST: BATCH 0720 / 1000\n",
            "TEST: BATCH 0721 / 1000\n",
            "TEST: BATCH 0722 / 1000\n",
            "TEST: BATCH 0723 / 1000\n",
            "TEST: BATCH 0724 / 1000\n",
            "TEST: BATCH 0725 / 1000\n",
            "TEST: BATCH 0726 / 1000\n",
            "TEST: BATCH 0727 / 1000\n",
            "TEST: BATCH 0728 / 1000\n",
            "TEST: BATCH 0729 / 1000\n",
            "TEST: BATCH 0730 / 1000\n",
            "TEST: BATCH 0731 / 1000\n",
            "TEST: BATCH 0732 / 1000\n",
            "TEST: BATCH 0733 / 1000\n",
            "TEST: BATCH 0734 / 1000\n",
            "TEST: BATCH 0735 / 1000\n",
            "TEST: BATCH 0736 / 1000\n",
            "TEST: BATCH 0737 / 1000\n",
            "TEST: BATCH 0738 / 1000\n",
            "TEST: BATCH 0739 / 1000\n",
            "TEST: BATCH 0740 / 1000\n",
            "TEST: BATCH 0741 / 1000\n",
            "TEST: BATCH 0742 / 1000\n",
            "TEST: BATCH 0743 / 1000\n",
            "TEST: BATCH 0744 / 1000\n",
            "TEST: BATCH 0745 / 1000\n",
            "TEST: BATCH 0746 / 1000\n",
            "TEST: BATCH 0747 / 1000\n",
            "TEST: BATCH 0748 / 1000\n",
            "TEST: BATCH 0749 / 1000\n",
            "TEST: BATCH 0750 / 1000\n",
            "TEST: BATCH 0751 / 1000\n",
            "TEST: BATCH 0752 / 1000\n",
            "TEST: BATCH 0753 / 1000\n",
            "TEST: BATCH 0754 / 1000\n",
            "TEST: BATCH 0755 / 1000\n",
            "TEST: BATCH 0756 / 1000\n",
            "TEST: BATCH 0757 / 1000\n",
            "TEST: BATCH 0758 / 1000\n",
            "TEST: BATCH 0759 / 1000\n",
            "TEST: BATCH 0760 / 1000\n",
            "TEST: BATCH 0761 / 1000\n",
            "TEST: BATCH 0762 / 1000\n",
            "TEST: BATCH 0763 / 1000\n",
            "TEST: BATCH 0764 / 1000\n",
            "TEST: BATCH 0765 / 1000\n",
            "TEST: BATCH 0766 / 1000\n",
            "TEST: BATCH 0767 / 1000\n",
            "TEST: BATCH 0768 / 1000\n",
            "TEST: BATCH 0769 / 1000\n",
            "TEST: BATCH 0770 / 1000\n",
            "TEST: BATCH 0771 / 1000\n",
            "TEST: BATCH 0772 / 1000\n",
            "TEST: BATCH 0773 / 1000\n",
            "TEST: BATCH 0774 / 1000\n",
            "TEST: BATCH 0775 / 1000\n",
            "TEST: BATCH 0776 / 1000\n",
            "TEST: BATCH 0777 / 1000\n",
            "TEST: BATCH 0778 / 1000\n",
            "TEST: BATCH 0779 / 1000\n",
            "TEST: BATCH 0780 / 1000\n",
            "TEST: BATCH 0781 / 1000\n",
            "TEST: BATCH 0782 / 1000\n",
            "TEST: BATCH 0783 / 1000\n",
            "TEST: BATCH 0784 / 1000\n",
            "TEST: BATCH 0785 / 1000\n",
            "TEST: BATCH 0786 / 1000\n",
            "TEST: BATCH 0787 / 1000\n",
            "TEST: BATCH 0788 / 1000\n",
            "TEST: BATCH 0789 / 1000\n",
            "TEST: BATCH 0790 / 1000\n",
            "TEST: BATCH 0791 / 1000\n",
            "TEST: BATCH 0792 / 1000\n",
            "TEST: BATCH 0793 / 1000\n",
            "TEST: BATCH 0794 / 1000\n",
            "TEST: BATCH 0795 / 1000\n",
            "TEST: BATCH 0796 / 1000\n",
            "TEST: BATCH 0797 / 1000\n",
            "TEST: BATCH 0798 / 1000\n",
            "TEST: BATCH 0799 / 1000\n",
            "TEST: BATCH 0800 / 1000\n",
            "TEST: BATCH 0801 / 1000\n",
            "TEST: BATCH 0802 / 1000\n",
            "TEST: BATCH 0803 / 1000\n",
            "TEST: BATCH 0804 / 1000\n",
            "TEST: BATCH 0805 / 1000\n",
            "TEST: BATCH 0806 / 1000\n",
            "TEST: BATCH 0807 / 1000\n",
            "TEST: BATCH 0808 / 1000\n",
            "TEST: BATCH 0809 / 1000\n",
            "TEST: BATCH 0810 / 1000\n",
            "TEST: BATCH 0811 / 1000\n",
            "TEST: BATCH 0812 / 1000\n",
            "TEST: BATCH 0813 / 1000\n",
            "TEST: BATCH 0814 / 1000\n",
            "TEST: BATCH 0815 / 1000\n",
            "TEST: BATCH 0816 / 1000\n",
            "TEST: BATCH 0817 / 1000\n",
            "TEST: BATCH 0818 / 1000\n",
            "TEST: BATCH 0819 / 1000\n",
            "TEST: BATCH 0820 / 1000\n",
            "TEST: BATCH 0821 / 1000\n",
            "TEST: BATCH 0822 / 1000\n",
            "TEST: BATCH 0823 / 1000\n",
            "TEST: BATCH 0824 / 1000\n",
            "TEST: BATCH 0825 / 1000\n",
            "TEST: BATCH 0826 / 1000\n",
            "TEST: BATCH 0827 / 1000\n",
            "TEST: BATCH 0828 / 1000\n",
            "TEST: BATCH 0829 / 1000\n",
            "TEST: BATCH 0830 / 1000\n",
            "TEST: BATCH 0831 / 1000\n",
            "TEST: BATCH 0832 / 1000\n",
            "TEST: BATCH 0833 / 1000\n",
            "TEST: BATCH 0834 / 1000\n",
            "TEST: BATCH 0835 / 1000\n",
            "TEST: BATCH 0836 / 1000\n",
            "TEST: BATCH 0837 / 1000\n",
            "TEST: BATCH 0838 / 1000\n",
            "TEST: BATCH 0839 / 1000\n",
            "TEST: BATCH 0840 / 1000\n",
            "TEST: BATCH 0841 / 1000\n",
            "TEST: BATCH 0842 / 1000\n",
            "TEST: BATCH 0843 / 1000\n",
            "TEST: BATCH 0844 / 1000\n",
            "TEST: BATCH 0845 / 1000\n",
            "TEST: BATCH 0846 / 1000\n",
            "TEST: BATCH 0847 / 1000\n",
            "TEST: BATCH 0848 / 1000\n",
            "TEST: BATCH 0849 / 1000\n",
            "TEST: BATCH 0850 / 1000\n",
            "TEST: BATCH 0851 / 1000\n",
            "TEST: BATCH 0852 / 1000\n",
            "TEST: BATCH 0853 / 1000\n",
            "TEST: BATCH 0854 / 1000\n",
            "TEST: BATCH 0855 / 1000\n",
            "TEST: BATCH 0856 / 1000\n",
            "TEST: BATCH 0857 / 1000\n",
            "TEST: BATCH 0858 / 1000\n",
            "TEST: BATCH 0859 / 1000\n",
            "TEST: BATCH 0860 / 1000\n",
            "TEST: BATCH 0861 / 1000\n",
            "TEST: BATCH 0862 / 1000\n",
            "TEST: BATCH 0863 / 1000\n",
            "TEST: BATCH 0864 / 1000\n",
            "TEST: BATCH 0865 / 1000\n",
            "TEST: BATCH 0866 / 1000\n",
            "TEST: BATCH 0867 / 1000\n",
            "TEST: BATCH 0868 / 1000\n",
            "TEST: BATCH 0869 / 1000\n",
            "TEST: BATCH 0870 / 1000\n",
            "TEST: BATCH 0871 / 1000\n",
            "TEST: BATCH 0872 / 1000\n",
            "TEST: BATCH 0873 / 1000\n",
            "TEST: BATCH 0874 / 1000\n",
            "TEST: BATCH 0875 / 1000\n",
            "TEST: BATCH 0876 / 1000\n",
            "TEST: BATCH 0877 / 1000\n",
            "TEST: BATCH 0878 / 1000\n",
            "TEST: BATCH 0879 / 1000\n",
            "TEST: BATCH 0880 / 1000\n",
            "TEST: BATCH 0881 / 1000\n",
            "TEST: BATCH 0882 / 1000\n",
            "TEST: BATCH 0883 / 1000\n",
            "TEST: BATCH 0884 / 1000\n",
            "TEST: BATCH 0885 / 1000\n",
            "TEST: BATCH 0886 / 1000\n",
            "TEST: BATCH 0887 / 1000\n",
            "TEST: BATCH 0888 / 1000\n",
            "TEST: BATCH 0889 / 1000\n",
            "TEST: BATCH 0890 / 1000\n",
            "TEST: BATCH 0891 / 1000\n",
            "TEST: BATCH 0892 / 1000\n",
            "TEST: BATCH 0893 / 1000\n",
            "TEST: BATCH 0894 / 1000\n",
            "TEST: BATCH 0895 / 1000\n",
            "TEST: BATCH 0896 / 1000\n",
            "TEST: BATCH 0897 / 1000\n",
            "TEST: BATCH 0898 / 1000\n",
            "TEST: BATCH 0899 / 1000\n",
            "TEST: BATCH 0900 / 1000\n",
            "TEST: BATCH 0901 / 1000\n",
            "TEST: BATCH 0902 / 1000\n",
            "TEST: BATCH 0903 / 1000\n",
            "TEST: BATCH 0904 / 1000\n",
            "TEST: BATCH 0905 / 1000\n",
            "TEST: BATCH 0906 / 1000\n",
            "TEST: BATCH 0907 / 1000\n",
            "TEST: BATCH 0908 / 1000\n",
            "TEST: BATCH 0909 / 1000\n",
            "TEST: BATCH 0910 / 1000\n",
            "TEST: BATCH 0911 / 1000\n",
            "TEST: BATCH 0912 / 1000\n",
            "TEST: BATCH 0913 / 1000\n",
            "TEST: BATCH 0914 / 1000\n",
            "TEST: BATCH 0915 / 1000\n",
            "TEST: BATCH 0916 / 1000\n",
            "TEST: BATCH 0917 / 1000\n",
            "TEST: BATCH 0918 / 1000\n",
            "TEST: BATCH 0919 / 1000\n",
            "TEST: BATCH 0920 / 1000\n",
            "TEST: BATCH 0921 / 1000\n",
            "TEST: BATCH 0922 / 1000\n",
            "TEST: BATCH 0923 / 1000\n",
            "TEST: BATCH 0924 / 1000\n",
            "TEST: BATCH 0925 / 1000\n",
            "TEST: BATCH 0926 / 1000\n",
            "TEST: BATCH 0927 / 1000\n",
            "TEST: BATCH 0928 / 1000\n",
            "TEST: BATCH 0929 / 1000\n",
            "TEST: BATCH 0930 / 1000\n",
            "TEST: BATCH 0931 / 1000\n",
            "TEST: BATCH 0932 / 1000\n",
            "TEST: BATCH 0933 / 1000\n",
            "TEST: BATCH 0934 / 1000\n",
            "TEST: BATCH 0935 / 1000\n",
            "TEST: BATCH 0936 / 1000\n",
            "TEST: BATCH 0937 / 1000\n",
            "TEST: BATCH 0938 / 1000\n",
            "TEST: BATCH 0939 / 1000\n",
            "TEST: BATCH 0940 / 1000\n",
            "TEST: BATCH 0941 / 1000\n",
            "TEST: BATCH 0942 / 1000\n",
            "TEST: BATCH 0943 / 1000\n",
            "TEST: BATCH 0944 / 1000\n",
            "TEST: BATCH 0945 / 1000\n",
            "TEST: BATCH 0946 / 1000\n",
            "TEST: BATCH 0947 / 1000\n",
            "TEST: BATCH 0948 / 1000\n",
            "TEST: BATCH 0949 / 1000\n",
            "TEST: BATCH 0950 / 1000\n",
            "TEST: BATCH 0951 / 1000\n",
            "TEST: BATCH 0952 / 1000\n",
            "TEST: BATCH 0953 / 1000\n",
            "TEST: BATCH 0954 / 1000\n",
            "TEST: BATCH 0955 / 1000\n",
            "TEST: BATCH 0956 / 1000\n",
            "TEST: BATCH 0957 / 1000\n",
            "TEST: BATCH 0958 / 1000\n",
            "TEST: BATCH 0959 / 1000\n",
            "TEST: BATCH 0960 / 1000\n",
            "TEST: BATCH 0961 / 1000\n",
            "TEST: BATCH 0962 / 1000\n",
            "TEST: BATCH 0963 / 1000\n",
            "TEST: BATCH 0964 / 1000\n",
            "TEST: BATCH 0965 / 1000\n",
            "TEST: BATCH 0966 / 1000\n",
            "TEST: BATCH 0967 / 1000\n",
            "TEST: BATCH 0968 / 1000\n",
            "TEST: BATCH 0969 / 1000\n",
            "TEST: BATCH 0970 / 1000\n",
            "TEST: BATCH 0971 / 1000\n",
            "TEST: BATCH 0972 / 1000\n",
            "TEST: BATCH 0973 / 1000\n",
            "TEST: BATCH 0974 / 1000\n",
            "TEST: BATCH 0975 / 1000\n",
            "TEST: BATCH 0976 / 1000\n",
            "TEST: BATCH 0977 / 1000\n",
            "TEST: BATCH 0978 / 1000\n",
            "TEST: BATCH 0979 / 1000\n",
            "TEST: BATCH 0980 / 1000\n",
            "TEST: BATCH 0981 / 1000\n",
            "TEST: BATCH 0982 / 1000\n",
            "TEST: BATCH 0983 / 1000\n",
            "TEST: BATCH 0984 / 1000\n",
            "TEST: BATCH 0985 / 1000\n",
            "TEST: BATCH 0986 / 1000\n",
            "TEST: BATCH 0987 / 1000\n",
            "TEST: BATCH 0988 / 1000\n",
            "TEST: BATCH 0989 / 1000\n",
            "TEST: BATCH 0990 / 1000\n",
            "TEST: BATCH 0991 / 1000\n",
            "TEST: BATCH 0992 / 1000\n",
            "TEST: BATCH 0993 / 1000\n",
            "TEST: BATCH 0994 / 1000\n",
            "TEST: BATCH 0995 / 1000\n",
            "TEST: BATCH 0996 / 1000\n",
            "TEST: BATCH 0997 / 1000\n",
            "TEST: BATCH 0998 / 1000\n",
            "TEST: BATCH 0999 / 1000\n",
            "TEST: BATCH 1000 / 1000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}